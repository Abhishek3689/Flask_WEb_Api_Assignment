{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5668b90b-7dc3-4edc-9b48-1d21b4c54f5a",
   "metadata": {},
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cace861-8434-4272-9443-cd907aabdb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Web scraping is a term used to describe the use of a program or algorithm to extract and process large amounts of data from the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b424546-bafc-4736-94fa-49a8ed08bdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Suppose you need data in web and there is no direct way to download it, web scraping using Python is a skill you can use to extract the data into a useful form that can be imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b40020ac-d849-4942-b9b9-67e8198eb5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The data on the websites are unstructured. Web scraping helps collect these unstructured data and store it in a structured form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25b24b6f-6b5d-4531-a03d-ab32fbe967dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3 Areas where it is useful\n",
    "## It is used for comparison of product prices from online shopping site\n",
    "## It is used in twitter to find out whats trending\n",
    "## It is used to find out hotel rating and reviews from a travel website"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef336ea0-350b-4d3e-b6bb-4c5ffadb5937",
   "metadata": {},
   "source": [
    "Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34887a3d-f780-44c7-93d1-45c100105ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## There are multiple ways of doing Webscraping .Some common methods are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6953992-756e-44db-aa69-f81cb3c21707",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Manual Scrapping-Copy and paste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "827eca52-6301-4918-a95c-2dd93606e86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Automated Scrapping\n",
    "## 1 . HTML PARSING\n",
    "## 2. DOM PARSING\n",
    "## 3. XPATH\n",
    "## 4. GOOGLE SHEETS\n",
    "## 5.Text Pattern matching\n",
    "## 6 Beautiful Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b1c5ee-2bfb-42a2-a6e9-85f86e813790",
   "metadata": {},
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7acf32c2-3ce4-4442-b6a3-8a2776736b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Beautiful Soup is a Python library that is used for web scraping purposes to pull the data out of HTML and XML files\n",
    "## It creates a parse tree from page source code that can be used to extract data in a hierarchical and more readable manner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfba6dc-fbd8-48ab-97b3-c5dc57c64e45",
   "metadata": {},
   "source": [
    "Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e73b169-56e9-4b80-a178-0cb598c04d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Flask is a lightweight framework to build websites. Weâ€™ll use this to parse our collected data and display it as HTML in a new HTML file.\n",
    "## The requests module allows us to send http requests to the website we want to scrape.\n",
    "## Flask can be used to create a simple web application that exposes the scraped data to end-users through a user-friendly interface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3d33f2-d69a-42aa-a686-658cacc55b66",
   "metadata": {},
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bffd9a4b-2dc5-499c-89f9-624bf04c2625",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We have used code pipeline and elastic beanstalk serives of AWS for use in the project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d75361bc-07e9-476e-87a2-bc82a526d60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## first we need to put the project in github from there we need to deploy in AWS Beanstalk so we will use codepipeline\n",
    "##  AWS CodePipeline simplifies the process of continuous delivery by automating the building, testing, and deployment of your software changes\n",
    "## Elastic Beanstalk can be used to deploy and manage your web application in a scalable and cost-effective manner. \n",
    "## Once CodePipeline deploys your code changes to Elastic Beanstalk, it can automatically handle the scaling and\n",
    "## management of the underlying infrastructure required to run your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080256bf-abf3-4a09-97ea-3cd73ef2f1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
